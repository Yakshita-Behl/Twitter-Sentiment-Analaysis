{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "import string\n",
    "import numpy as np\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "training_data = pd.read_csv(\"C:\\\\Users\\\\karti\\\\Downloads\\\\training_data.csv\")\n",
    "testing_data = pd.read_csv(\"C:\\\\Users\\\\karti\\\\Downloads\\\\testing_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>569934458364813313</td>\n",
       "      <td>neutral</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cottopanama85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir followback</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 10:58:58 -0800</td>\n",
       "      <td>ohio,panama</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>568564006329434113</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaulBEsteves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united thanks for the help. Wish the phone re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 16:13:17 -0800</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>569643648910028801</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>runfixsteve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@usairways the. Worst. Ever. #dca #customerser...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 15:43:24 -0800</td>\n",
       "      <td>St. Augustine, Florida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>568864981917110272</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLChicosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@nrhodes85: look! Another apology. DO NOT FLY ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 12:09:15 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>568929299350179840</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JW_Blocker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@united you are by far the worst airline. 4 pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:24:49 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment     airline  \\\n",
       "0      567900433542488064          negative   Southwest   \n",
       "1      569989168903819264          positive   Southwest   \n",
       "2      568089179520954368          positive      United   \n",
       "3      568928195581513728          negative   Southwest   \n",
       "4      568594180014014464          negative      United   \n",
       "...                   ...               ...         ...   \n",
       "10975  569934458364813313           neutral    American   \n",
       "10976  568564006329434113          positive      United   \n",
       "10977  569643648910028801          negative  US Airways   \n",
       "10978  568864981917110272          negative  US Airways   \n",
       "10979  568929299350179840          negative      United   \n",
       "\n",
       "      airline_sentiment_gold           name negativereason_gold  \\\n",
       "0                        NaN  ColeyGirouard                 NaN   \n",
       "1                        NaN  WalterFaddoul                 NaN   \n",
       "2                        NaN      LocalKyle                 NaN   \n",
       "3                        NaN    amccarthy19                 NaN   \n",
       "4                        NaN        J_Okayy                 NaN   \n",
       "...                      ...            ...                 ...   \n",
       "10975                    NaN  Cottopanama85                 NaN   \n",
       "10976                    NaN   PaulBEsteves                 NaN   \n",
       "10977                    NaN    runfixsteve                 NaN   \n",
       "10978                    NaN     CLChicosky                 NaN   \n",
       "10979                    NaN     JW_Blocker                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "0                  0  @SouthwestAir I am scheduled for the morning, ...   \n",
       "1                  0  @SouthwestAir seeing your workers time in and ...   \n",
       "2                  0  @united Flew ORD to Miami and back and  had gr...   \n",
       "3                  0     @SouthwestAir @dultch97 that's horse radish üò§üê¥   \n",
       "4                  0  @united so our flight into ORD was delayed bec...   \n",
       "...              ...                                                ...   \n",
       "10975              0                            @AmericanAir followback   \n",
       "10976              0  @united thanks for the help. Wish the phone re...   \n",
       "10977              0  @usairways the. Worst. Ever. #dca #customerser...   \n",
       "10978              0  @nrhodes85: look! Another apology. DO NOT FLY ...   \n",
       "10979              1  @united you are by far the worst airline. 4 pl...   \n",
       "\n",
       "      tweet_coord              tweet_created              tweet_location  \\\n",
       "0             NaN  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1             NaN  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2             NaN  2015-02-18 08:46:29 -0800                    Illinois   \n",
       "3             NaN  2015-02-20 16:20:26 -0800                         NaN   \n",
       "4             NaN  2015-02-19 18:13:11 -0800                         NaN   \n",
       "...           ...                        ...                         ...   \n",
       "10975         NaN  2015-02-23 10:58:58 -0800                 ohio,panama   \n",
       "10976         NaN  2015-02-19 16:13:17 -0800                    Brooklyn   \n",
       "10977         NaN  2015-02-22 15:43:24 -0800      St. Augustine, Florida   \n",
       "10978         NaN  2015-02-20 12:09:15 -0800                         NaN   \n",
       "10979         NaN  2015-02-20 16:24:49 -0800                         NaN   \n",
       "\n",
       "                    user_timezone  \n",
       "0          Atlantic Time (Canada)  \n",
       "1      Central Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3          Atlantic Time (Canada)  \n",
       "4      Eastern Time (US & Canada)  \n",
       "...                           ...  \n",
       "10975                         NaN  \n",
       "10976  Eastern Time (US & Canada)  \n",
       "10977                         NaN  \n",
       "10978                         NaN  \n",
       "10979                         NaN  \n",
       "\n",
       "[10980 rows x 12 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569682010270101504</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zsalim03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 18:15:50 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569608307184242688</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sa_craig</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir after all, the plane didn‚Äôt land ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 13:22:57 -0800</td>\n",
       "      <td>College Station, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567879304593408001</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DanaChristos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 18:52:31 -0800</td>\n",
       "      <td>CT</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569757651539660801</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rossj987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 23:16:24 -0800</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>569900705852608513</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tranpham18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 08:44:51 -0800</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>570304244001193984</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anthony_Scerri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways Been stuck for 40+ minutes due to l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:28:22 -0800</td>\n",
       "      <td>Astoria, NY</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>567847737061941249</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mttdprkr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways 4 hours... 4 hours... FOUR HOURS.  ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 16:47:05 -0800</td>\n",
       "      <td>Vancouver, WA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>567823564167192576</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>miaerolinea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Nice RT @VirginAmerica: The man of steel might...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 15:11:02 -0800</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>Caracas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>570273819287531520</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GoldensPleasure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Aww Thanks AA..DFW was on GMA up ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 09:27:28 -0800</td>\n",
       "      <td>East Coast     CT.</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>569341769114128386</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>suntoshi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united the lounge tells us they have no pillo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 19:43:50 -0800</td>\n",
       "      <td>Bedford, Nh</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3660 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id         airline airline_sentiment_gold  \\\n",
       "0     569682010270101504        American                    NaN   \n",
       "1     569608307184242688        American                    NaN   \n",
       "2     567879304593408001       Southwest                    NaN   \n",
       "3     569757651539660801      US Airways                    NaN   \n",
       "4     569900705852608513        American                    NaN   \n",
       "...                  ...             ...                    ...   \n",
       "3655  570304244001193984      US Airways                    NaN   \n",
       "3656  567847737061941249      US Airways                    NaN   \n",
       "3657  567823564167192576  Virgin America                    NaN   \n",
       "3658  570273819287531520        American                    NaN   \n",
       "3659  569341769114128386          United                    NaN   \n",
       "\n",
       "                 name negativereason_gold  retweet_count  \\\n",
       "0            zsalim03                 NaN              0   \n",
       "1            sa_craig                 NaN              0   \n",
       "2        DanaChristos                 NaN              1   \n",
       "3            rossj987                 NaN              0   \n",
       "4          tranpham18                 NaN              0   \n",
       "...               ...                 ...            ...   \n",
       "3655   Anthony_Scerri                 NaN              0   \n",
       "3656         mttdprkr                 NaN              0   \n",
       "3657      miaerolinea                 NaN              1   \n",
       "3658  GoldensPleasure                 NaN              0   \n",
       "3659         suntoshi                 NaN              0   \n",
       "\n",
       "                                                   text tweet_coord  \\\n",
       "0     @AmericanAir In car gng to DFW. Pulled over 1h...         NaN   \n",
       "1     @AmericanAir after all, the plane didn‚Äôt land ...         NaN   \n",
       "2     @SouthwestAir can't believe how many paying cu...         NaN   \n",
       "3     @USAirways I can legitimately say that I would...         NaN   \n",
       "4     @AmericanAir still no response from AA. great ...         NaN   \n",
       "...                                                 ...         ...   \n",
       "3655  @USAirways Been stuck for 40+ minutes due to l...         NaN   \n",
       "3656  @USAirways 4 hours... 4 hours... FOUR HOURS.  ...         NaN   \n",
       "3657  Nice RT @VirginAmerica: The man of steel might...         NaN   \n",
       "3658  @AmericanAir Aww Thanks AA..DFW was on GMA up ...         NaN   \n",
       "3659  @united the lounge tells us they have no pillo...         NaN   \n",
       "\n",
       "                  tweet_created       tweet_location  \\\n",
       "0     2015-02-22 18:15:50 -0800                Texas   \n",
       "1     2015-02-22 13:22:57 -0800  College Station, TX   \n",
       "2     2015-02-17 18:52:31 -0800                   CT   \n",
       "3     2015-02-22 23:16:24 -0800     Washington, D.C.   \n",
       "4     2015-02-23 08:44:51 -0800        New York City   \n",
       "...                         ...                  ...   \n",
       "3655  2015-02-24 11:28:22 -0800          Astoria, NY   \n",
       "3656  2015-02-17 16:47:05 -0800        Vancouver, WA   \n",
       "3657  2015-02-17 15:11:02 -0800            Worldwide   \n",
       "3658  2015-02-24 09:27:28 -0800   East Coast     CT.   \n",
       "3659  2015-02-21 19:43:50 -0800          Bedford, Nh   \n",
       "\n",
       "                   user_timezone  \n",
       "0     Central Time (US & Canada)  \n",
       "1     Central Time (US & Canada)  \n",
       "2     Eastern Time (US & Canada)  \n",
       "3     Eastern Time (US & Canada)  \n",
       "4     Eastern Time (US & Canada)  \n",
       "...                          ...  \n",
       "3655                       Quito  \n",
       "3656  Pacific Time (US & Canada)  \n",
       "3657                     Caracas  \n",
       "3658  Central Time (US & Canada)  \n",
       "3659  Eastern Time (US & Canada)  \n",
       "\n",
       "[3660 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10980 10980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'SouthwestAir',\n",
       " 'I',\n",
       " 'am',\n",
       " 'scheduled',\n",
       " 'for',\n",
       " 'the',\n",
       " 'morning',\n",
       " ',',\n",
       " '2',\n",
       " 'days',\n",
       " 'after',\n",
       " 'the',\n",
       " 'fact',\n",
       " ',',\n",
       " 'yes',\n",
       " '..',\n",
       " 'not',\n",
       " 'sure',\n",
       " 'why',\n",
       " 'my',\n",
       " 'evening',\n",
       " 'flight',\n",
       " 'was',\n",
       " 'the',\n",
       " 'only',\n",
       " 'one',\n",
       " 'Cancelled',\n",
       " 'Flightled']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the x_train and y_train data from training_data\n",
    "x_train = training_data['text']\n",
    "y_train = training_data['airline_sentiment']\n",
    "print(len(x_train), len(y_train))\n",
    "word_tokenize(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['@',\n",
       " 'AmericanAir',\n",
       " 'In',\n",
       " 'car',\n",
       " 'gng',\n",
       " 'to',\n",
       " 'DFW',\n",
       " '.',\n",
       " 'Pulled',\n",
       " 'over',\n",
       " '1hr',\n",
       " 'ago',\n",
       " '-',\n",
       " 'very',\n",
       " 'icy',\n",
       " 'roads',\n",
       " '.',\n",
       " 'On-hold',\n",
       " 'with',\n",
       " 'AA',\n",
       " 'since',\n",
       " '1hr',\n",
       " '.',\n",
       " 'Ca',\n",
       " \"n't\",\n",
       " 'reach',\n",
       " 'arpt',\n",
       " 'for',\n",
       " 'AA2450',\n",
       " '.',\n",
       " 'Wat',\n",
       " '2',\n",
       " 'do',\n",
       " '?']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the x_test data from testing_data\n",
    "x_test = testing_data['text']\n",
    "print(len(x_test))\n",
    "word_tokenize(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_doc = []\n",
    "for i in range(len(x_train)):\n",
    "    words = word_tokenize(x_train[i])\n",
    "    training_doc.append((words, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['@',\n",
       "   'SouthwestAir',\n",
       "   'I',\n",
       "   'am',\n",
       "   'scheduled',\n",
       "   'for',\n",
       "   'the',\n",
       "   'morning',\n",
       "   ',',\n",
       "   '2',\n",
       "   'days',\n",
       "   'after',\n",
       "   'the',\n",
       "   'fact',\n",
       "   ',',\n",
       "   'yes',\n",
       "   '..',\n",
       "   'not',\n",
       "   'sure',\n",
       "   'why',\n",
       "   'my',\n",
       "   'evening',\n",
       "   'flight',\n",
       "   'was',\n",
       "   'the',\n",
       "   'only',\n",
       "   'one',\n",
       "   'Cancelled',\n",
       "   'Flightled'],\n",
       "  'negative'),\n",
       " (['@',\n",
       "   'SouthwestAir',\n",
       "   'seeing',\n",
       "   'your',\n",
       "   'workers',\n",
       "   'time',\n",
       "   'in',\n",
       "   'and',\n",
       "   'time',\n",
       "   'out',\n",
       "   'going',\n",
       "   'above',\n",
       "   'and',\n",
       "   'beyond',\n",
       "   'is',\n",
       "   'why',\n",
       "   'I',\n",
       "   'love',\n",
       "   'flying',\n",
       "   'with',\n",
       "   'you',\n",
       "   'guys',\n",
       "   '.',\n",
       "   'Thank',\n",
       "   'you',\n",
       "   '!'],\n",
       "  'positive'),\n",
       " (['@',\n",
       "   'united',\n",
       "   'Flew',\n",
       "   'ORD',\n",
       "   'to',\n",
       "   'Miami',\n",
       "   'and',\n",
       "   'back',\n",
       "   'and',\n",
       "   'had',\n",
       "   'great',\n",
       "   'crew',\n",
       "   ',',\n",
       "   'service',\n",
       "   'on',\n",
       "   'both',\n",
       "   'legs',\n",
       "   '.',\n",
       "   'THANKS'],\n",
       "  'positive'),\n",
       " (['@',\n",
       "   'SouthwestAir',\n",
       "   '@',\n",
       "   'dultch97',\n",
       "   'that',\n",
       "   \"'s\",\n",
       "   'horse',\n",
       "   'radish',\n",
       "   'üò§üê¥'],\n",
       "  'negative'),\n",
       " (['@',\n",
       "   'united',\n",
       "   'so',\n",
       "   'our',\n",
       "   'flight',\n",
       "   'into',\n",
       "   'ORD',\n",
       "   'was',\n",
       "   'delayed',\n",
       "   'because',\n",
       "   'of',\n",
       "   'Air',\n",
       "   'Force',\n",
       "   'One',\n",
       "   ',',\n",
       "   'but',\n",
       "   'the',\n",
       "   'last',\n",
       "   'flight',\n",
       "   'to',\n",
       "   'SBN',\n",
       "   'is',\n",
       "   'at',\n",
       "   '8:20',\n",
       "   ',',\n",
       "   '5',\n",
       "   'mins',\n",
       "   'from',\n",
       "   'now',\n",
       "   'we',\n",
       "   'just',\n",
       "   'landed',\n",
       "   '.'],\n",
       "  'negative')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_doc = []\n",
    "for i in range(len(x_test)):\n",
    "    words = word_tokenize(x_test[i])\n",
    "    testing_doc.append((words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['@',\n",
       "  'AmericanAir',\n",
       "  'In',\n",
       "  'car',\n",
       "  'gng',\n",
       "  'to',\n",
       "  'DFW',\n",
       "  '.',\n",
       "  'Pulled',\n",
       "  'over',\n",
       "  '1hr',\n",
       "  'ago',\n",
       "  '-',\n",
       "  'very',\n",
       "  'icy',\n",
       "  'roads',\n",
       "  '.',\n",
       "  'On-hold',\n",
       "  'with',\n",
       "  'AA',\n",
       "  'since',\n",
       "  '1hr',\n",
       "  '.',\n",
       "  'Ca',\n",
       "  \"n't\",\n",
       "  'reach',\n",
       "  'arpt',\n",
       "  'for',\n",
       "  'AA2450',\n",
       "  '.',\n",
       "  'Wat',\n",
       "  '2',\n",
       "  'do',\n",
       "  '?'],\n",
       " ['@',\n",
       "  'AmericanAir',\n",
       "  'after',\n",
       "  'all',\n",
       "  ',',\n",
       "  'the',\n",
       "  'plane',\n",
       "  'didn',\n",
       "  '‚Äô',\n",
       "  't',\n",
       "  'land',\n",
       "  'in',\n",
       "  'identical',\n",
       "  'or',\n",
       "  'worse',\n",
       "  ')',\n",
       "  'conditions',\n",
       "  'at',\n",
       "  'GRK',\n",
       "  'according',\n",
       "  'to',\n",
       "  'METARs',\n",
       "  '.'],\n",
       " ['@',\n",
       "  'SouthwestAir',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  'believe',\n",
       "  'how',\n",
       "  'many',\n",
       "  'paying',\n",
       "  'customers',\n",
       "  'you',\n",
       "  'left',\n",
       "  'high',\n",
       "  'and',\n",
       "  'dry',\n",
       "  'with',\n",
       "  'no',\n",
       "  'reason',\n",
       "  'for',\n",
       "  'flight',\n",
       "  'Cancelled',\n",
       "  'Flightlations',\n",
       "  'Monday',\n",
       "  'out',\n",
       "  'of',\n",
       "  'BDL',\n",
       "  '!',\n",
       "  'Wow',\n",
       "  '.'],\n",
       " ['@',\n",
       "  'USAirways',\n",
       "  'I',\n",
       "  'can',\n",
       "  'legitimately',\n",
       "  'say',\n",
       "  'that',\n",
       "  'I',\n",
       "  'would',\n",
       "  'have',\n",
       "  'rather',\n",
       "  'driven',\n",
       "  'cross',\n",
       "  'country',\n",
       "  'than',\n",
       "  'flown',\n",
       "  'on',\n",
       "  'US',\n",
       "  'Airways',\n",
       "  '.'],\n",
       " ['@',\n",
       "  'AmericanAir',\n",
       "  'still',\n",
       "  'no',\n",
       "  'response',\n",
       "  'from',\n",
       "  'AA',\n",
       "  '.',\n",
       "  'great',\n",
       "  'job',\n",
       "  'guys',\n",
       "  '!']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_doc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.update(list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(words):\n",
    "    output_words = []\n",
    "    for word in words:\n",
    "        if word.lower() not in stop_words:\n",
    "            pos = pos_tag([word])\n",
    "            clean_word = lemmmatizer.lemmatize(word, pos = get_simple_pos(pos[0][1]))\n",
    "            output_words.append(clean_word)\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_training_doc = [(clean_review(word_list), category) for word_list, category in training_doc]\n",
    "clean_testing_doc = [(clean_review(word_list)) for word_list in testing_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['SouthwestAir',\n",
       "  'schedule',\n",
       "  'morning',\n",
       "  '2',\n",
       "  'day',\n",
       "  'fact',\n",
       "  'yes',\n",
       "  '..',\n",
       "  'sure',\n",
       "  'even',\n",
       "  'flight',\n",
       "  'one',\n",
       "  'Cancelled',\n",
       "  'Flightled'],\n",
       " 'negative')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_training_doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AmericanAir',\n",
       " 'car',\n",
       " 'gng',\n",
       " 'DFW',\n",
       " 'Pulled',\n",
       " '1hr',\n",
       " 'ago',\n",
       " 'icy',\n",
       " 'road',\n",
       " 'On-hold',\n",
       " 'AA',\n",
       " 'since',\n",
       " '1hr',\n",
       " 'Ca',\n",
       " \"n't\",\n",
       " 'reach',\n",
       " 'arpt',\n",
       " 'AA2450',\n",
       " 'Wat',\n",
       " '2']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_testing_doc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COUNT VECTORIZER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [category for doc, category in clean_training_doc]\n",
    "x_train = [\" \".join(doc) for doc, category in clean_training_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\" \".join(doc) for doc in clean_testing_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SouthwestAir schedule morning 2 day fact yes .. sure even flight one Cancelled Flightled'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AmericanAir car gng DFW Pulled 1hr ago icy road On-hold AA since 1hr Ca n't reach arpt AA2450 Wat 2\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPERIMENT WITH NGRAMS AND TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer(max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = count_vec.fit_transform(x_train)\n",
    "x_train_features = a.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0016',\n",
       " '00pm',\n",
       " '02',\n",
       " '03',\n",
       " '05',\n",
       " '05am',\n",
       " '05pm',\n",
       " '08',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1007',\n",
       " '101',\n",
       " '1027',\n",
       " '103',\n",
       " '1041',\n",
       " '105',\n",
       " '1051',\n",
       " '1071',\n",
       " '1080',\n",
       " '1098',\n",
       " '10a',\n",
       " '10am',\n",
       " '10hrs',\n",
       " '10mins',\n",
       " '10pm',\n",
       " '10th',\n",
       " '11',\n",
       " '117',\n",
       " '1171',\n",
       " '118',\n",
       " '11a',\n",
       " '11am',\n",
       " '11pm',\n",
       " '11th',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '1230',\n",
       " '1242',\n",
       " '1254',\n",
       " '12am',\n",
       " '12b',\n",
       " '13',\n",
       " '130',\n",
       " '1357',\n",
       " '1359',\n",
       " '136',\n",
       " '1388',\n",
       " '1389',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '1472',\n",
       " '1491',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '1503',\n",
       " '1514',\n",
       " '152',\n",
       " '1531',\n",
       " '1533',\n",
       " '1535',\n",
       " '1547',\n",
       " '1562',\n",
       " '1583',\n",
       " '15minutes',\n",
       " '15th',\n",
       " '16',\n",
       " '1625',\n",
       " '1644',\n",
       " '1657',\n",
       " '1679',\n",
       " '17',\n",
       " '1700',\n",
       " '1701',\n",
       " '1706',\n",
       " '1715',\n",
       " '174',\n",
       " '1750',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '1808',\n",
       " '1826',\n",
       " '1861',\n",
       " '188',\n",
       " '1898',\n",
       " '19',\n",
       " '190',\n",
       " '1917',\n",
       " '195',\n",
       " '1970',\n",
       " '1971',\n",
       " '1997',\n",
       " '1am',\n",
       " '1hr',\n",
       " '1k',\n",
       " '1pm',\n",
       " '1st',\n",
       " '1way',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2012',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2034',\n",
       " '20l',\n",
       " '20min',\n",
       " '20pm',\n",
       " '21',\n",
       " '2168',\n",
       " '21st',\n",
       " '22',\n",
       " '2222',\n",
       " '2258',\n",
       " '23',\n",
       " '2324',\n",
       " '2396',\n",
       " '23rd',\n",
       " '24',\n",
       " '2401',\n",
       " '2470',\n",
       " '249',\n",
       " '24h',\n",
       " '24hr',\n",
       " '24hrs',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '2586',\n",
       " '25th',\n",
       " '26',\n",
       " '2692',\n",
       " '27',\n",
       " '275',\n",
       " '27l',\n",
       " '28',\n",
       " '28th',\n",
       " '29',\n",
       " '2955',\n",
       " '2990176298',\n",
       " '2am',\n",
       " '2b',\n",
       " '2bestfriends',\n",
       " '2boh2mh3cb',\n",
       " '2chng',\n",
       " '2d',\n",
       " '2day',\n",
       " '2days',\n",
       " '2dayslate',\n",
       " '2daysofhell',\n",
       " '2edgc6tbls',\n",
       " '2fails',\n",
       " '2gether',\n",
       " '2go',\n",
       " '2hours',\n",
       " '2hourwaitsucks',\n",
       " '2hr',\n",
       " '2hr15min',\n",
       " '2hr30',\n",
       " '2hr30min',\n",
       " '2hrs',\n",
       " '2ikbp8gxwi',\n",
       " '2ir7ynmbdu',\n",
       " '2k',\n",
       " '2littlebirds',\n",
       " '2maro',\n",
       " '2min',\n",
       " '2mins',\n",
       " '2morrow',\n",
       " '2nd',\n",
       " '2ndary',\n",
       " '2nite',\n",
       " '2npxb6obmr',\n",
       " '2nt',\n",
       " '2ny5tuxfqf',\n",
       " '2nzh3qoazo',\n",
       " '2of2',\n",
       " '2oz',\n",
       " '2plains',\n",
       " '2pm',\n",
       " '2pujvcelng',\n",
       " '2qjbcv5jzq',\n",
       " '2rsw',\n",
       " '2thc9rkurt',\n",
       " '2uaicfjrms',\n",
       " '2wks',\n",
       " '2x',\n",
       " '2xdaily',\n",
       " '2xjvun66zz',\n",
       " '2y',\n",
       " '2yr',\n",
       " '2z3hgqprsg',\n",
       " '2z3jv73ilw',\n",
       " '2zm4jkalzl',\n",
       " '30',\n",
       " '300',\n",
       " '30000ft',\n",
       " '3001408092',\n",
       " '3001885409',\n",
       " '300er',\n",
       " '304',\n",
       " '3040',\n",
       " '305',\n",
       " '3056',\n",
       " '307',\n",
       " '3075',\n",
       " '3076',\n",
       " '3078',\n",
       " '30a',\n",
       " '30am',\n",
       " '30k',\n",
       " '30min',\n",
       " '30mins',\n",
       " '30pm',\n",
       " '30th',\n",
       " '30timesenough',\n",
       " '31',\n",
       " '310',\n",
       " '3104',\n",
       " '3113',\n",
       " '3121',\n",
       " '3127',\n",
       " '3130',\n",
       " '314505529',\n",
       " '317',\n",
       " '3198',\n",
       " '31cfhtk60r',\n",
       " '31daysofoscar',\n",
       " '32',\n",
       " '320',\n",
       " '3200',\n",
       " '320008a',\n",
       " '3231dtw',\n",
       " '324',\n",
       " '325',\n",
       " '3252',\n",
       " '3260',\n",
       " '3267',\n",
       " '3277',\n",
       " '329',\n",
       " '33',\n",
       " '330',\n",
       " '33036',\n",
       " '3312',\n",
       " '336',\n",
       " '34',\n",
       " '35',\n",
       " '350',\n",
       " '35pm',\n",
       " '35x',\n",
       " '36',\n",
       " '360',\n",
       " '362',\n",
       " '3659',\n",
       " '37',\n",
       " '3739',\n",
       " '3750',\n",
       " '382',\n",
       " '386',\n",
       " '39',\n",
       " '3am',\n",
       " '3d',\n",
       " '3days',\n",
       " '3fq3xelbon',\n",
       " '3hrs',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '3thparty',\n",
       " '3x',\n",
       " '3yr',\n",
       " '40',\n",
       " '400',\n",
       " '400er',\n",
       " '403',\n",
       " '404',\n",
       " '40min',\n",
       " '40mins',\n",
       " '40pm',\n",
       " '40th',\n",
       " '413',\n",
       " '4146',\n",
       " '415',\n",
       " '41g',\n",
       " '42',\n",
       " '424',\n",
       " '428',\n",
       " '4322',\n",
       " '433',\n",
       " '435',\n",
       " '44',\n",
       " '440',\n",
       " '4420',\n",
       " '4435',\n",
       " '4438',\n",
       " '4443',\n",
       " '445',\n",
       " '4487',\n",
       " '45',\n",
       " '450',\n",
       " '4524',\n",
       " '454',\n",
       " '4567',\n",
       " '45am',\n",
       " '45min',\n",
       " '45mins',\n",
       " '45pm',\n",
       " '46',\n",
       " '462',\n",
       " '4649',\n",
       " '4663',\n",
       " '47',\n",
       " '475',\n",
       " '48',\n",
       " '4840',\n",
       " '49',\n",
       " '494',\n",
       " '4am',\n",
       " '4hr',\n",
       " '4hrs',\n",
       " '4ojrsdwpkk',\n",
       " '4pm',\n",
       " '4th',\n",
       " '4ward',\n",
       " '4x',\n",
       " '50',\n",
       " '500',\n",
       " '501',\n",
       " '5015',\n",
       " '5080',\n",
       " '50am',\n",
       " '50k',\n",
       " '50pm',\n",
       " '51',\n",
       " '52',\n",
       " '53',\n",
       " '530',\n",
       " '5350',\n",
       " '55',\n",
       " '5534',\n",
       " '556',\n",
       " '55am',\n",
       " '55pm',\n",
       " '56',\n",
       " '561',\n",
       " '58',\n",
       " '59',\n",
       " '5957',\n",
       " '597',\n",
       " '599',\n",
       " '5am',\n",
       " '5hr',\n",
       " '5hrs',\n",
       " '5pm',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '606',\n",
       " '619',\n",
       " '62',\n",
       " '622',\n",
       " '623',\n",
       " '630',\n",
       " '636',\n",
       " '6373',\n",
       " '639',\n",
       " '645',\n",
       " '64gb',\n",
       " '65',\n",
       " '653',\n",
       " '654',\n",
       " '669',\n",
       " '672',\n",
       " '68',\n",
       " '683',\n",
       " '686',\n",
       " '699',\n",
       " '6am',\n",
       " '6hrs',\n",
       " '6pm',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '703',\n",
       " '719',\n",
       " '72',\n",
       " '723',\n",
       " '728',\n",
       " '72rmpkogwu',\n",
       " '73',\n",
       " '7300',\n",
       " '737',\n",
       " '738',\n",
       " '7403607771',\n",
       " '746',\n",
       " '747',\n",
       " '75',\n",
       " '750',\n",
       " '757',\n",
       " '767',\n",
       " '768',\n",
       " '7700',\n",
       " '777',\n",
       " '787',\n",
       " '788',\n",
       " '79',\n",
       " '795',\n",
       " '799',\n",
       " '7am',\n",
       " '7d',\n",
       " '7pm',\n",
       " '7t1rdrcre6',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '805',\n",
       " '80th',\n",
       " '810',\n",
       " '830',\n",
       " '834',\n",
       " '837',\n",
       " '85832',\n",
       " '86',\n",
       " '883',\n",
       " '894',\n",
       " '8am',\n",
       " '8aug',\n",
       " '8b',\n",
       " '8h',\n",
       " '8hr',\n",
       " '8hrs',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8wbzorrn3c',\n",
       " '90',\n",
       " '900',\n",
       " '915',\n",
       " '917',\n",
       " '919',\n",
       " '95',\n",
       " '952',\n",
       " '953',\n",
       " '989',\n",
       " '99',\n",
       " '9am',\n",
       " '9pm',\n",
       " 'a1',\n",
       " 'a320',\n",
       " 'a321',\n",
       " 'aa',\n",
       " 'aa106',\n",
       " 'aa199',\n",
       " 'aa2444',\n",
       " 'aa4285',\n",
       " 'aa65',\n",
       " 'aa76',\n",
       " 'aa953',\n",
       " 'aadvantage',\n",
       " 'aafail',\n",
       " 'aarp',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'abq',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abuse',\n",
       " 'abysmal',\n",
       " 'ac',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'acct',\n",
       " 'accts',\n",
       " 'accurate',\n",
       " 'accuse',\n",
       " 'acknowledge',\n",
       " 'acknowledgment',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'addtl',\n",
       " 'adjacent',\n",
       " 'adjustment',\n",
       " 'admiral',\n",
       " 'admirals',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'adore',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'advertise',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advisory',\n",
       " 'aerojobmarket',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affiliate',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afraid',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'aggravate',\n",
       " 'aggressive',\n",
       " 'agnt',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agt',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahhhh',\n",
       " 'ahold',\n",
       " 'ai',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airbus',\n",
       " 'aircanada',\n",
       " 'aircraft',\n",
       " 'airfare',\n",
       " 'airline',\n",
       " 'airlinegeeks',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airway',\n",
       " 'airways',\n",
       " 'aisle',\n",
       " 'aka',\n",
       " 'alaska',\n",
       " 'albany',\n",
       " 'albuquerque',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'ali',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allende',\n",
       " 'allergic',\n",
       " 'allergy',\n",
       " 'alleviate',\n",
       " 'alliance',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'always',\n",
       " 'alwayslate',\n",
       " 'am',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanairlines',\n",
       " 'americanview',\n",
       " 'amex',\n",
       " 'amm',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amybruni',\n",
       " 'ana',\n",
       " 'anamarketers',\n",
       " 'and',\n",
       " 'andrew',\n",
       " 'andrew_wasila',\n",
       " 'andrews',\n",
       " 'aneqxzr4bp',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angry',\n",
       " 'ann',\n",
       " 'annettenaif',\n",
       " 'anniversary',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annricord',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answerthephone',\n",
       " 'anthony',\n",
       " 'anticipate',\n",
       " 'antonio',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'any',\n",
       " 'any1',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologizes',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'appalled',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approx',\n",
       " 'apps',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aqjn4hwnac',\n",
       " 'arbitrary',\n",
       " 'ardent',\n",
       " 'are',\n",
       " 'area',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arizona',\n",
       " 'armrest',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'article',\n",
       " 'aruba',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ase',\n",
       " 'ashamed',\n",
       " 'asia',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'askpaypal',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspen',\n",
       " 'assault',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assign',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'associate',\n",
       " 'assult',\n",
       " 'assume',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'astound',\n",
       " 'at',\n",
       " 'atc',\n",
       " 'athlete',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atrocious',\n",
       " 'attach',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attendee',\n",
       " 'attention',\n",
       " 'attentiveness',\n",
       " 'attitude',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'auh',\n",
       " 'aus',\n",
       " 'austin',\n",
       " 'austinairport',\n",
       " 'australia',\n",
       " 'auto',\n",
       " 'automate',\n",
       " 'automatically',\n",
       " 'autoresponse',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'average',\n",
       " 'avgeek',\n",
       " 'aviation',\n",
       " 'avis',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awesomeness',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'az',\n",
       " 'b1',\n",
       " 'b11',\n",
       " 'b12',\n",
       " 'b16',\n",
       " 'b4',\n",
       " 'b6',\n",
       " 'b737',\n",
       " 'b767',\n",
       " 'b787',\n",
       " 'b8',\n",
       " 'ba',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'backlog',\n",
       " 'backpack',\n",
       " 'backup',\n",
       " 'bad',\n",
       " 'badcustomerservice',\n",
       " 'badge',\n",
       " 'badly',\n",
       " 'badmgmt',\n",
       " 'badservice',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'bagage',\n",
       " 'baggage',\n",
       " 'baggagelost',\n",
       " 'bags',\n",
       " 'bahamas',\n",
       " 'bait',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'balls',\n",
       " 'baltimore',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bandwidth',\n",
       " 'bangkok',\n",
       " 'bank',\n",
       " 'bankrupt',\n",
       " 'bar',\n",
       " 'barbados',\n",
       " 'barbara',\n",
       " 'barely',\n",
       " 'base',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basket',\n",
       " 'bathroom',\n",
       " 'battery',\n",
       " 'battierccipuppy',\n",
       " 'batting',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'battling',\n",
       " 'bay',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'bdl',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beanie',\n",
       " 'beantownmatty',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'beer',\n",
       " 'before',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'behalf',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'belfast',\n",
       " 'believe',\n",
       " 'belize',\n",
       " 'bellagio',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'belt',\n",
       " 'benefit',\n",
       " 'bereavement',\n",
       " 'bergstrom',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bestairline',\n",
       " 'bestairlineever',\n",
       " 'bestemployees',\n",
       " 'bestflightever',\n",
       " 'besty',\n",
       " 'bet',\n",
       " 'betsy',\n",
       " 'better',\n",
       " 'beverage',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bgm',\n",
       " 'bgr',\n",
       " 'bhm',\n",
       " 'bicycle',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'billing',\n",
       " 'billion',\n",
       " 'bin',\n",
       " 'bio',\n",
       " 'bird',\n",
       " 'birmingham',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackhistorymonth',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'blasting',\n",
       " 'blatant',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blizzard',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'bluecarpet',\n",
       " 'bluemanity',\n",
       " 'bna',\n",
       " 'board',\n",
       " 'boarded',\n",
       " 'boarding',\n",
       " 'boat',\n",
       " 'boeing',\n",
       " 'boeingairplanes',\n",
       " 'bogota',\n",
       " 'boise',\n",
       " 'bold',\n",
       " 'bom',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'boom',\n",
       " 'boot',\n",
       " 'booze',\n",
       " 'bora',\n",
       " 'border',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bostonlogan',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bougth',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bqn',\n",
       " 'brag',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brandloveaffair',\n",
       " 'brandmance',\n",
       " 'brandssayingbae',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'breach',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breath',\n",
       " 'bretharold',\n",
       " 'brian',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'british_airways',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brokenpromises',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'browser',\n",
       " 'bruh',\n",
       " 'brushing',\n",
       " 'brutal',\n",
       " 'bs',\n",
       " 'btr',\n",
       " 'bttr',\n",
       " 'btv',\n",
       " 'btw',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buenos',\n",
       " ...]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = count_vec.transform(x_test)\n",
    "x_test_features = b.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLY SKLEARN CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(x_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svc.predict(x_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'negative', ..., 'neutral', 'positive',\n",
       "       'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING THE PREDICTIONS TO CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3660, 3660)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test_features), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3660"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "file = open(\"twitter_sentiment_output.csv\", \"w\")\n",
    "wtr = csv.writer(file, delimiter=',', lineterminator='\\n')\n",
    "count = 0\n",
    "for x in y_pred : \n",
    "    count += 1\n",
    "\n",
    "    wtr.writerow ([x])\n",
    "count"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
